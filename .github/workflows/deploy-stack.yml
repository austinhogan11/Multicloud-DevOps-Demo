name: Deploy Full Stack (Infra + Backend + Frontend)

on:
  push:
    branches: [ main ]
    paths:
      - 'app/**'
      - 'frontend/**'
      - 'infra/**'
      - '.github/workflows/deploy-stack.yml'
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    env:
      LAMBDA_FUNCTION: ${{ vars.LAMBDA_FUNCTION || '' }}
      # Optional fallbacks if Terraform state/outputs are not configured
      FALLBACK_API_BASE: ${{ vars.VITE_API_BASE || vars.VITE_API_URL }}
      FALLBACK_S3_BUCKET: ${{ vars.S3_BUCKET }}
      FALLBACK_CF_DIST_ID: ${{ vars.CF_DISTRIBUTION_ID }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Read region from tfvars
        id: tfvars
        run: |
          FILE=infra/aws/live/us-east-1/app/dev.tfvars
          REGION=$(awk -F'=' '/^aws_region/ {gsub(/[ "\r\t]/,"",$2); print $2}' "$FILE")
          if [ -z "$REGION" ]; then REGION=us-east-1; fi
          echo "region=$REGION" >> "$GITHUB_OUTPUT"

      - name: Inspect OIDC token (debug)
        if: ${{ env.DEBUG_OIDC == '1' }}
        id: oidc
        uses: actions/github-script@v7
        with:
          script: |
            const t = await core.getIDToken('sts.amazonaws.com');
            const payload = JSON.parse(Buffer.from(t.split('.')[1], 'base64').toString());
            core.setOutput('sub', payload.sub);
            core.setOutput('aud', payload.aud);
            core.setOutput('ref', process.env.GITHUB_REF || '');
            core.setOutput('repo', process.env.GITHUB_REPOSITORY || '');
      - run: |
          echo "OIDC sub=${{ steps.oidc.outputs.sub }}"
          echo "OIDC aud=${{ steps.oidc.outputs.aud }}"
          echo "ref=${{ steps.oidc.outputs.ref }}"
          echo "repo=${{ steps.oidc.outputs.repo }}"

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ steps.tfvars.outputs.region || 'us-east-1' }}
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          role-session-name: GitHubActionsDeployment

      - name: Sanity check Terraform backend
        run: |
          set -e
          if [ -n "${{ vars.TF_STATE_BUCKET }}" ] && [ -n "${{ vars.TF_STATE_KEY }}" ]; then
            echo "Checking S3 bucket: ${{ vars.TF_STATE_BUCKET }}"
            if aws s3api head-bucket --bucket "${{ vars.TF_STATE_BUCKET }}" 2>/dev/null; then
              echo "✓ S3 state bucket is accessible"
            else
              echo "::error::S3 bucket '${{ vars.TF_STATE_BUCKET }}' not found or not accessible by the assumed role"
              exit 1
            fi

            if [ -n "${{ vars.TF_LOCK_TABLE }}" ]; then
              echo "Checking DynamoDB lock table: ${{ vars.TF_LOCK_TABLE }}"
              if aws dynamodb describe-table --table-name "${{ vars.TF_LOCK_TABLE }}" >/dev/null 2>&1; then
                echo "✓ DynamoDB lock table is accessible"
              else
                echo "::error::DynamoDB table '${{ vars.TF_LOCK_TABLE }}' not found or not accessible by the assumed role"
                exit 1
              fi
            else
              echo "No TF_LOCK_TABLE provided (proceeding without state locking)"
            fi
          else
            echo "TF_STATE_* not set; Terraform apply will be skipped later."
          fi

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.7.5

      - name: Build lambda.zip (Python 3.12, linux/amd64)
        run: |
          rm -rf build && mkdir -p build/deps
          docker run --rm --platform linux/amd64 \
            -v "$PWD":/var/task -w /var/task \
            --entrypoint /bin/sh public.ecr.aws/sam/build-python3.12:latest -lc '
              python -V && pip install --upgrade pip setuptools wheel && \
              pip install --no-cache-dir -r app/requirements.txt -t build/deps
            '
          cp -r app build/deps/
          (cd build/deps && zip -qr ../lambda.zip .)

      - name: Terraform init/apply (if backend configured)
        id: tf
        working-directory: infra/aws/live/us-east-1/app
        env:
          TF_IN_AUTOMATION: 1
          # Optional Splunk wiring from repo vars/secrets
          SPLUNK_HEC_URL: ${{ vars.SPLUNK_HEC_URL }}
          SPLUNK_HEC_TOKEN: ${{ secrets.SPLUNK_HEC_TOKEN }}
          SPLUNK_INDEX: ${{ vars.SPLUNK_INDEX }}
          SPLUNK_SOURCE: ${{ vars.SPLUNK_SOURCE }}
          SPLUNK_SOURCETYPE: ${{ vars.SPLUNK_SOURCETYPE }}
          SPLUNK_ENABLE: ${{ vars.SPLUNK_ENABLE || '1' }}
        run: |
          set -e
          if [ -n "${{ vars.TF_STATE_BUCKET }}" ] && [ -n "${{ vars.TF_STATE_KEY }}" ]; then
            INIT_ARGS=("-upgrade" "-backend-config=bucket=${{ vars.TF_STATE_BUCKET }}" "-backend-config=key=${{ vars.TF_STATE_KEY }}" "-backend-config=region=${{ steps.tfvars.outputs.region }}")
            if [ -n "${{ vars.TF_LOCK_TABLE }}" ]; then INIT_ARGS+=("-backend-config=dynamodb_table=${{ vars.TF_LOCK_TABLE }}"); fi
            terraform init "${INIT_ARGS[@]}"
            # Conditionally pass Splunk variables if provided
            EXTRA_VARS=()
            [ -n "${SPLUNK_HEC_URL}" ] && EXTRA_VARS+=("-var=splunk_hec_url=${SPLUNK_HEC_URL}")
            [ -n "${SPLUNK_HEC_TOKEN}" ] && EXTRA_VARS+=("-var=splunk_hec_token=${SPLUNK_HEC_TOKEN}")
            [ -n "${SPLUNK_INDEX}" ] && EXTRA_VARS+=("-var=splunk_index=${SPLUNK_INDEX}")
            [ -n "${SPLUNK_SOURCE}" ] && EXTRA_VARS+=("-var=splunk_source=${SPLUNK_SOURCE}")
            [ -n "${SPLUNK_SOURCETYPE}" ] && EXTRA_VARS+=("-var=splunk_sourcetype=${SPLUNK_SOURCETYPE}")
            [ -n "${SPLUNK_ENABLE}" ] && EXTRA_VARS+=("-var=splunk_enable=${SPLUNK_ENABLE}")
            terraform apply -auto-approve -var-file=dev.tfvars "${EXTRA_VARS[@]}"
            terraform output -json > $GITHUB_WORKSPACE/tf_outputs.json
            echo "tf_outputs=true" >> $GITHUB_OUTPUT
          else
            echo "No TF_STATE_* provided; skipping Terraform apply."
            echo "tf_outputs=false" >> $GITHUB_OUTPUT
          fi

      - name: Derive deployment values
        id: derive
        run: |
          set -e
          if [ "${{ steps.tf.outputs.tf_outputs }}" = "true" ]; then
            API_BASE=$(jq -r .api_base_url.value tf_outputs.json)
            BUCKET=$(jq -r .frontend_bucket.value tf_outputs.json)
            CFID=$(jq -r .cf_distribution_id.value tf_outputs.json)
            LAMBDA_NAME=$(jq -r .lambda_name.value tf_outputs.json)
            LAMBDA_ARN=$(jq -r .lambda_arn.value tf_outputs.json)
          else
            API_BASE="${FALLBACK_API_BASE}"
            BUCKET="${FALLBACK_S3_BUCKET}"
            CFID="${FALLBACK_CF_DIST_ID}"
            LAMBDA_NAME="${LAMBDA_FUNCTION}"
            LAMBDA_ARN=""
          fi
          echo "api_base=$API_BASE" >> $GITHUB_OUTPUT
          echo "bucket=$BUCKET" >> $GITHUB_OUTPUT
          echo "cfid=$CFID" >> $GITHUB_OUTPUT
          echo "lambda_name=$LAMBDA_NAME" >> $GITHUB_OUTPUT
          echo "lambda_arn=$LAMBDA_ARN" >> $GITHUB_OUTPUT

      - name: Show derived values and probe API
        run: |
          echo "API_BASE=${{ steps.derive.outputs.api_base }}"
          echo "BUCKET=${{ steps.derive.outputs.bucket }}"
          echo "CF_DIST_ID=${{ steps.derive.outputs.cfid }}"
          echo "LAMBDA_NAME=${{ steps.derive.outputs.lambda_name }}"
          if command -v curl >/dev/null 2>&1 && [ -n "${{ steps.derive.outputs.api_base }}" ]; then
            echo "Probing API health..."
            set +e
            curl -fsSL "${{ steps.derive.outputs.api_base }}/health" || true
            echo ""  # newline
            set -e
          fi

      - name: Inspect Lambda config (CORS)
        run: |
          set -e
          NAME="${{ steps.derive.outputs.lambda_name }}"
          if [ -n "$NAME" ]; then
            echo "Fetching environment for $NAME"
            aws lambda get-function-configuration --function-name "$NAME" \
              --query 'Environment.Variables' --output json || true
          else
            echo "No lambda name derived; skipping"
          fi

      - name: Verify CORS preflight
        run: |
          set -e
          API="${{ steps.derive.outputs.api_base }}"
          ORIGIN="https://${{ steps.derive.outputs.bucket }}.s3.amazonaws.com" # fallback if CF domain not available
          # Prefer CloudFront domain when present by querying distribution domain via AWS CLI
          if [ -n "${{ steps.derive.outputs.cfid }}" ]; then
            CF_DOMAIN=$(aws cloudfront get-distribution --id "${{ steps.derive.outputs.cfid }}" --query 'Distribution.DomainName' --output text 2>/dev/null || true)
            if [ -n "$CF_DOMAIN" ] && [ "$CF_DOMAIN" != "None" ]; then ORIGIN="https://$CF_DOMAIN"; fi
          fi
          if [ -n "$API" ]; then
            echo "OPTIONS $API/tasks/ with Origin: $ORIGIN"
            curl -i -X OPTIONS \
              -H "Origin: $ORIGIN" \
              -H "Access-Control-Request-Method: GET" \
              "$API/tasks/" | sed -n '1,20p'
          else
            echo "No API base to verify CORS against."
          fi

      - name: Update Lambda code
        run: |
          TARGET_FN="${{ steps.derive.outputs.lambda_arn }}"
          if [ -z "$TARGET_FN" ]; then TARGET_FN="${{ steps.derive.outputs.lambda_name }}"; fi
          aws lambda update-function-code --function-name "$TARGET_FN" --zip-file fileb://build/lambda.zip > /dev/null

      - name: Build frontend
        working-directory: frontend
        run: |
          echo "VITE_API_BASE=${{ steps.derive.outputs.api_base }}" | tee .env .env.production >/dev/null
          npm ci
          npm run build

      - name: Verify frontend uses expected API URL
        run: |
          set -e
          API="${{ steps.derive.outputs.api_base }}"
          if [ -z "$API" ]; then
            echo "::warning::No API base derived; skipping verification"
            exit 0
          fi
          echo "Looking for API URL in built assets: $API"
          if grep -R -n --binary-files=text "$API" frontend/dist >/dev/null 2>&1; then
            echo "✓ Found API URL in built assets"
          else
            echo "::error::Built assets do not reference $API. Check VITE_API_BASE during build."
            grep -R -n --binary-files=text -E "execute-api|VITE_API_BASE" frontend/dist || true
            exit 1
          fi

      - name: Sync to S3
        run: |
          export AWS_DEFAULT_REGION=${{ steps.tfvars.outputs.region }}
          aws s3 sync frontend/dist/ "s3://${{ steps.derive.outputs.bucket }}" --delete
          aws s3 cp frontend/dist/index.html "s3://${{ steps.derive.outputs.bucket }}/index.html" \
            --cache-control "max-age=60,public" --content-type "text/html"

      - name: Invalidate CloudFront
        if: ${{ steps.derive.outputs.cfid != '' }}
        run: |
          export AWS_DEFAULT_REGION=${{ steps.tfvars.outputs.region }}
          aws cloudfront create-invalidation --distribution-id "${{ steps.derive.outputs.cfid }}" --paths "/*"
